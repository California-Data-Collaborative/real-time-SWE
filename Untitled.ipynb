{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "from datetime import date, timedelta\n",
    "import boto3\n",
    "import os \n",
    "import io\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "bucket = 'cadc-snowbot'\n",
    "s3_client = boto3.client('s3')\n",
    "s3_resource = boto3.resource('s3')\n",
    "\n",
    "stationIDs = getStationDetails().ID\n",
    "first_date = '1980-07-02'\n",
    "today = str(date.today())\n",
    "yesterday = str(date.today()-timedelta(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/stationNames.csv')\n",
    "df = df[['ID', 'Longitude', 'Latitude', 'ElevationFeet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStationDetails():\n",
    "    df = pd.read_csv('data/stationNames.csv', thousands=',')\n",
    "    return(df[['ID', 'Longitude', 'Latitude', 'ElevationFeet']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateHistorical(sens=3, start_date=first_date, end_date=today):  \n",
    "    st = '3LK'\n",
    "    url = f'http://cdec.water.ca.gov/dynamicapp/req/CSVDataServlet?Stations={st}&SensorNums={sens}&dur_code=D&Start={start_date}&End={end_date}'\n",
    "    \n",
    "    df_raw = pd.read_csv(url)\n",
    "    df_raw['station_id'] = st\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for st in stationIDs[1:]:\n",
    "        url = f'http://cdec.water.ca.gov/dynamicapp/req/CSVDataServlet?Stations={st}&SensorNums={sens}&dur_code=D&Start={start_date}&End={end_date}'\n",
    "        tmp = pd.read_csv(url)\n",
    "        \n",
    "        df_raw = df_raw.append(tmp)\n",
    "        \n",
    "        tmp['date'] = [datetime.datetime.strptime(i[:8], '%Y%m%d').date() \\\n",
    "                       for i in tmp['DATE TIME']]\n",
    "        tmp = tmp[['date', 'VALUE']]\n",
    "        tmp.columns = ['date', st]\n",
    "        tmp.set_index('date')\n",
    "\n",
    "        df = tmp if df.shape[0]==0 else df.merge(tmp, how='outer')        \n",
    "    \n",
    "    fname = f\"{today.replace('-','')}_{sens:02}\"\n",
    "    fnameBackup = f\"backup_{fname}.csv\"\n",
    "    fnameRaw = f\"raw_{fname}.csv\"\n",
    "    \n",
    "    return(df)\n",
    "#     df.to_csv(f\"data/{fnameBackup}\")\n",
    "#     df_raw.to_csv(f\"data/{fnameRaw}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens = 3\n",
    "start_date = yesterday\n",
    "end_date = yesterday\n",
    "\n",
    "\n",
    "st = '3LK'\n",
    "url = f'http://cdec.water.ca.gov/dynamicapp/req/CSVDataServlet?Stations={st}&SensorNums={sens}&dur_code=D&Start={start_date}&End={end_date}'\n",
    "\n",
    "df_raw = pd.read_csv(url)\n",
    "df_raw['station_id'] = st\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for st in stationIDs[1:]:\n",
    "    url = f'http://cdec.water.ca.gov/dynamicapp/req/CSVDataServlet?Stations={st}&SensorNums={sens}&dur_code=D&Start={start_date}&End={end_date}'\n",
    "    tmp = pd.read_csv(url)\n",
    "\n",
    "#     df_raw = df_raw.append(tmp)\n",
    "    tmp['date'] = [datetime.datetime.strptime(i[:8], '%Y%m%d').date() \\\n",
    "                   for i in tmp['DATE TIME']]\n",
    "    tmp = tmp[['date', 'VALUE']]\n",
    "    tmp.columns = ['date', st]\n",
    "    tmp.set_index('date')\n",
    "\n",
    "    df = tmp if df.shape[0]==0 else df.merge(tmp, how='outer')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts = getStationDetails().set_index('ID')\n",
    "todayData = df.T.iloc[1:]\n",
    "todayData = sts.merge(todayData, left_index=True, right_index=True)\n",
    "todayData = todayData.fillna('---')\n",
    "todayData['snow'] = pd.to_numeric(todayData[0], downcast='float', errors='coerce') * 0.0254\n",
    "\n",
    "snow_amt_with_locn_notnull = todayData.dropna()\n",
    "snow_amount_null = todayData[todayData.snow.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fetchData as fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yesterday' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-cc46f6d06e14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetToday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/work/argo/snowbot/fetchData.py\u001b[0m in \u001b[0;36mgetToday\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetToday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdateHistorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myesterday\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myesterday\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'yesterday' is not defined"
     ]
    }
   ],
   "source": [
    "tmp = fd.getToday()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (snow_amt_with_locn_notnull.shape[0] != 0 and snow_amt_with_locn_notnull.shape[0] != 1):\n",
    "      lons=np.array(snow_amt_with_locn_notnull['Longitude']) \n",
    "      lons = lons[~np.isnan(lons)]\n",
    "\n",
    "      lats=np.array(snow_amt_with_locn_notnull['Latitude']) \n",
    "      lats = lats[~np.isnan(lats)]\n",
    "      elev=np.array(snow_amt_with_locn_notnull['ElevationFeet'])\n",
    "      snow_amount =np.array(snow_amt_with_locn_notnull['snow'])\n",
    "      # count the number of zeros in snow_amount\n",
    "      #print(snow_amount)\n",
    "      \n",
    "      zero_count = (snow_amount == 0.0).sum()\n",
    "      zero_count_fraction = (zero_count / snow_amount.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience (basic)",
   "language": "python",
   "name": "ds_basic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
